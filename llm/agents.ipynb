{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import Arctic, GPT\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(BaseModel):\n",
    "    name: str\n",
    "    description: str = Field(..., title=\"Description of the agent\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name, self.description\n",
    "    \n",
    "consultant = Agent(name=\"Consultant\", description=\"An agent to use when you need additional information or advice on a topic.\")\n",
    "sql_generator = Agent(name=\"SQL Generator\", description=\"An agent to use when you need to generate any SQL code.\")\n",
    "db_agent = Agent(name=\"Database Agent\", description=\"An agent to use when you need to interact with the app database, which user's may want to modify.\")\n",
    "\n",
    "agents = [consultant, sql_generator, db_agent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELF'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = [\"SELF\"] + [agent.name for agent in agents]\n",
    "\n",
    "# Assumptions:\n",
    "# - Only ONE agent can be assigned to a request\n",
    "# - Only ONE request is being handled at a time \n",
    "# (if we have multiple requests, we would need to loop through them with a GPT orchestrator calling this chain)\n",
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        f\"\"\"\n",
    "        You are a supervisor, tasked with managing user requests while having access to the\n",
    "        following members on your team: {agents}.\n",
    "\n",
    "        Given the following user request, classify it as being a request you could either fulfill yourself, or that\n",
    "        one of your team members could better handle. \n",
    "\n",
    "        Select one of: {options}\"\"\"\n",
    "        + \"\"\"\n",
    "        User Request: {request}\n",
    "        \"\"\"\n",
    "    )\n",
    "    | GPT(model=\"gpt-3.5-turbo\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# example to test validity of the chain\n",
    "chain.invoke({\"request\": \"Add 2 + 2.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create sub-chains to route to based on the output - SELF, Consultant,  or SQL Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-chain\n",
    "self_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"{request}\"\n",
    "    )\n",
    "    | GPT(model=\"gpt-3.5-turbo\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# consultant chain\n",
    "consultant_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"You are a helpful assistant. You have access to tools and resources that can help you provide\n",
    "        additional information or advice on a topic. Given the following user request, provide a response that\n",
    "        would be helpful to the user.\n",
    "\n",
    "        Request: {request}\"\"\"\n",
    "    )\n",
    "    | GPT(model=\"gpt-3.5-turbo\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# SQL Generator chain\n",
    "sql_generator_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"You are an expert data engineer that is very proficient in SQL. Given the following user request,\n",
    "        generate the SQL code that would fulfill the user's request.\n",
    "\n",
    "        Request: {request}\"\"\"\n",
    "    )\n",
    "    | Arctic()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "db_chain = (\n",
    "    RunnableLambda(lambda x: f\"Added {x} to the database.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(msg: str):\n",
    "\n",
    "    print(f\"\"\"Routed message {msg[\"request\"]} to {msg[\"topic\"]} agent.\"\"\")\n",
    "\n",
    "    if \"self\" in msg[\"topic\"].lower():\n",
    "        return self_chain\n",
    "    elif \"consultant\" in msg[\"topic\"].lower():\n",
    "        return consultant_chain\n",
    "    elif \"sql generator\" in msg[\"topic\"].lower():\n",
    "        return sql_generator_chain\n",
    "    elif \"database agent\" in msg[\"topic\"].lower():\n",
    "        return db_chain\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid agent {msg} selected.\")\n",
    "\n",
    "full_chain = {\"request\": lambda x: x[\"request\"], \"topic\": lambda x: chain.invoke(x)} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routed message What is the capital of France? to SELF agent.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"request\": \"What is the capital of France?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routed message Implement fizzbuzz in SQL. to SQL Generator agent.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a simple implementation of FizzBuzz in SQL:\\n\\n```sql\\nWITH RECURSIVE fizzbuzz AS (\\n    SELECT 1 as num\\n    UNION ALL\\n    SELECT num + 1 FROM fizzbuzz WHERE num < 100\\n)\\nSELECT \\n    CASE \\n        WHEN MOD(num, 3) = 0 AND MOD(num, 5) = 0 THEN 'FizzBuzz'\\n        WHEN MOD(num, 3) = 0 THEN 'Fizz'\\n        WHEN MOD(num, 5) = 0 THEN 'Buzz'\\n        ELSE CAST(num AS VARCHAR)\\n    END\\nFROM fizzbuzz;\\n```\\nThis script creates a recursive common table expression (CTE) that generates numbers from 1 to 100. Then it uses a `CASE` statement to print 'Fizz', 'Buzz', 'FizzBuzz', or the number itself based on the rules of FizzBuzz game.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"request\": \"Implement fizzbuzz in SQL.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routed message Add this customer's information to the database. to Database Agent agent.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Added {\\'request\\': \"Add this customer\\'s information to the database.\", \\'topic\\': \\'Database Agent\\'} to the database.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"request\": \"Add this customer's information to the database.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap ReAct agent around arctic and gpt and see if it works\n",
    "# if so, substitute the llms with the react agent in every chain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
